# å¼•æ“å¯¹æ¯”æµ‹è¯•å·¥å…·ä½¿ç”¨æŒ‡å— / Engine Benchmark Tool Guide

## ç®€ä»‹ / Introduction

è¿™æ˜¯ä¸€ä¸ªç”¨äºæµ‹è¯•å’Œå¯¹æ¯”ä¸åŒæ–‡æ¡£è½¬æ¢å¼•æ“æ€§èƒ½çš„å·¥å…·ã€‚å®ƒå¯ä»¥è‡ªåŠ¨æµ‹è¯•å¤šä¸ªå¼•æ“ï¼Œå¹¶ç”Ÿæˆè¯¦ç»†çš„ä¸­æ–‡å¯¹æ¯”æŠ¥å‘Šã€‚

This is a tool for testing and comparing the performance of different document conversion engines. It automatically tests multiple engines and generates detailed Chinese comparison reports.

## åŠŸèƒ½ç‰¹ç‚¹ / Features

- âœ… **è‡ªåŠ¨åŒ–æµ‹è¯•** - ä¸€é”®æµ‹è¯•å¤šä¸ªå¼•æ“ / Automated testing of multiple engines
- ğŸ“Š **æ€§èƒ½æŒ‡æ ‡** - è½¬æ¢æ—¶é—´ã€æˆåŠŸç‡ã€è¾“å‡ºè´¨é‡ / Performance metrics including conversion time, success rate, and output quality
- ğŸ“ **ä¸­æ–‡æŠ¥å‘Š** - ç”Ÿæˆè¯¦ç»†çš„ä¸­æ–‡å¯¹æ¯”åˆ†ææŠ¥å‘Š / Generate comprehensive Chinese comparison reports
- ğŸ¯ **å¼•æ“åˆ†æ** - æ¯ä¸ªå¼•æ“çš„ä¼˜ç¼ºç‚¹å’Œé€‚ç”¨åœºæ™¯ / Pros/cons and use cases for each engine
- ğŸ”§ **çµæ´»é…ç½®** - è‡ªå®šä¹‰æµ‹è¯•æ–‡ä»¶å’Œå¼•æ“é€‰æ‹© / Flexible configuration with custom test files and engine selection

## å¿«é€Ÿå¼€å§‹ / Quick Start

### åŸºæœ¬ç”¨æ³• / Basic Usage

```bash
# æµ‹è¯•æ‰€æœ‰å¯ç”¨å¼•æ“
# Test all available engines
python benchmark.py

# æµ‹è¯•ç‰¹å®šå¼•æ“
# Test specific engines
python benchmark.py --engines local markitdown

# ä½¿ç”¨è‡ªå®šä¹‰æµ‹è¯•æ–‡ä»¶
# Use custom test file
python benchmark.py --test-file path/to/your/document.pdf

# ä¿å­˜JSONæ ¼å¼ç»“æœ
# Save results in JSON format
python benchmark.py --save-json
```

### é«˜çº§ç”¨æ³• / Advanced Usage

```bash
# æµ‹è¯•å¤šä¸ªå¼•æ“å¹¶ä¿å­˜åˆ°æŒ‡å®šç›®å½•
# Test multiple engines and save to specific directory
python benchmark.py \
  --engines local markitdown paddleocr docling \
  --output-dir my_test_results \
  --save-json

# ä½¿ç”¨PDFæ–‡ä»¶æµ‹è¯•OCRå¼•æ“
# Test OCR engines with PDF file
python benchmark.py \
  --test-file document.pdf \
  --engines mistral deepseekocr paddleocr

# æµ‹è¯•æ‰€æœ‰æœ¬åœ°å¼•æ“ï¼ˆä¸éœ€è¦APIå¯†é’¥ï¼‰
# Test all local engines (no API keys required)
python benchmark.py \
  --engines local markitdown paddleocr docling marker mineru
```

## æ”¯æŒçš„å¼•æ“ / Supported Engines

### æœ¬åœ°å¼•æ“ / Local Engines (No API Key Required)

1. **local** - åŸºç¡€æ–‡æœ¬æå–å¼•æ“
   - ä¼˜ç‚¹ï¼šå¿«é€Ÿã€æ— éœ€ä¾èµ–ã€é€‚åˆçº¯æ–‡æœ¬
   - ç¼ºç‚¹ï¼šOCRèƒ½åŠ›æœ‰é™

2. **markitdown** - Microsoft MarkItDownå¼•æ“
   - ä¼˜ç‚¹ï¼šæ”¯æŒOfficeæ ¼å¼ã€æœ¬åœ°å¤„ç†ã€ä¿çœŸåº¦é«˜
   - ç¼ºç‚¹ï¼šéœ€è¦å®‰è£…ä¾èµ–åŒ…
   - å®‰è£…ï¼š`pip install markitdown`

3. **paddleocr** - PaddleOCRå¼•æ“
   - ä¼˜ç‚¹ï¼šæœ¬åœ°OCRã€æ”¯æŒå¤šè¯­è¨€ã€å¯GPUåŠ é€Ÿ
   - ç¼ºç‚¹ï¼šéœ€è¦ä¸‹è½½æ¨¡å‹
   - å®‰è£…ï¼š`pip install ".[paddleocr]"`

4. **docling** - IBM Doclingå¼•æ“
   - ä¼˜ç‚¹ï¼šä¼ä¸šçº§æ–¹æ¡ˆã€ç»“æ„åŒ–æå–
   - ç¼ºç‚¹ï¼šä¾èµ–è¾ƒé‡
   - å®‰è£…ï¼š`pip install ".[docling]"`

5. **marker** - Marker PDFå¼•æ“
   - ä¼˜ç‚¹ï¼šä¸“æ³¨PDFã€ä¿ç•™æ ¼å¼
   - ç¼ºç‚¹ï¼šéœ€è¦è¾ƒå¤šä¾èµ–
   - å®‰è£…ï¼š`pip install ".[marker]"`

6. **mineru** - MinerUå¼•æ“
   - ä¼˜ç‚¹ï¼šå¤šç§è§£ææ–¹æ³•ã€GPUåŠ é€Ÿ
   - ç¼ºç‚¹ï¼šèµ„æºæ¶ˆè€—å¤§
   - å®‰è£…ï¼š`pip install ".[mineru]"`

### äº‘ç«¯å¼•æ“ / Cloud Engines (API Key Required)

7. **mistral** - Mistral OCR API
   - ä¼˜ç‚¹ï¼šå¼ºå¤§çš„OCRèƒ½åŠ›ã€é«˜è´¨é‡è¾“å‡º
   - ç¼ºç‚¹ï¼šéœ€è¦APIå¯†é’¥å’Œç½‘ç»œ
   - é…ç½®ï¼šåœ¨`.env`æ–‡ä»¶ä¸­è®¾ç½®`MISTRAL_API_KEY`

8. **deepseekocr** - DeepSeek OCR API
   - ä¼˜ç‚¹ï¼šä¼˜ç§€çš„ä¸­æ–‡OCRã€è§†è§‰ç†è§£èƒ½åŠ›å¼º
   - ç¼ºç‚¹ï¼šéœ€è¦APIå¯†é’¥å’Œç½‘ç»œ
   - é…ç½®ï¼šåœ¨`.env`æ–‡ä»¶ä¸­è®¾ç½®`SILICONFLOW_API_KEY`

## æŠ¥å‘Šå†…å®¹ / Report Contents

ç”Ÿæˆçš„ä¸­æ–‡å¯¹æ¯”æŠ¥å‘ŠåŒ…å«ä»¥ä¸‹å†…å®¹ï¼š

The generated Chinese comparison report includes:

### 1. æµ‹è¯•ä¿¡æ¯ / Test Information
- æµ‹è¯•æ—¶é—´ / Test timestamp
- æµ‹è¯•æ–‡ä»¶ä¿¡æ¯ / Test file information
- æ–‡ä»¶å¤§å° / File size
- æµ‹è¯•å¼•æ“æ•°é‡ / Number of engines tested

### 2. æ•´ä½“ç»Ÿè®¡ / Overall Statistics
- æˆåŠŸ/å¤±è´¥å¼•æ“æ•°é‡ / Number of successful/failed engines
- æˆåŠŸç‡ç™¾åˆ†æ¯” / Success rate percentage

### 3. æ€§èƒ½æ’å / Performance Rankings
- æŒ‰è½¬æ¢æ—¶é—´æ’åº / Sorted by conversion time
- è¾“å‡ºé•¿åº¦å¯¹æ¯” / Output length comparison
- èµ„æºæ•°é‡ç»Ÿè®¡ / Asset count statistics

### 4. è¯¦ç»†æµ‹è¯•ç»“æœè¡¨æ ¼ / Detailed Results Table
åŒ…å«æ¯ä¸ªå¼•æ“çš„ï¼š
- çŠ¶æ€ï¼ˆæˆåŠŸ/å¤±è´¥ï¼‰/ Status (success/failure)
- è½¬æ¢æ—¶é—´ / Conversion time
- Markdownè¾“å‡ºé•¿åº¦ / Markdown output length
- èµ„æºæ•°é‡ / Number of assets
- æ€§èƒ½è¯„çº§ï¼ˆâ­è¯„åˆ†ï¼‰/ Performance rating (star rating)

### 5. å¼•æ“ç‰¹ç‚¹åˆ†æ / Engine Characteristics Analysis
æ¯ä¸ªå¼•æ“çš„è¯¦ç»†åˆ†æï¼ŒåŒ…æ‹¬ï¼š
- ä¼˜ç‚¹åˆ—è¡¨ / List of advantages
- ç¼ºç‚¹åˆ—è¡¨ / List of disadvantages
- æœ€é€‚åˆçš„ä½¿ç”¨åœºæ™¯ / Best use cases

### 6. ä½¿ç”¨å»ºè®® / Usage Recommendations
- é€Ÿåº¦ä¼˜å…ˆæ¨è / Speed-first recommendations
- è´¨é‡ä¼˜å…ˆæ¨è / Quality-first recommendations
- æˆæœ¬è€ƒè™‘ï¼ˆå…è´¹/ä»˜è´¹ï¼‰/ Cost considerations (free/paid)
- æŒ‰æ–‡æ¡£ç±»å‹çš„å»ºè®® / Recommendations by document type

### 7. å¤±è´¥è¯¦æƒ… / Failure Details
- å¤±è´¥å¼•æ“çš„é”™è¯¯ä¿¡æ¯ / Error messages for failed engines
- æ•…éšœè¯Šæ–­å»ºè®® / Troubleshooting suggestions

## ç¤ºä¾‹æŠ¥å‘Š / Sample Report

è¿è¡ŒåŸºå‡†æµ‹è¯•åï¼Œä¼šç”Ÿæˆç±»ä¼¼ä»¥ä¸‹çš„æŠ¥å‘Šï¼š

```markdown
# æ–‡æ¡£è½¬æ¢å¼•æ“å¯¹æ¯”æµ‹è¯•æŠ¥å‘Š

## æµ‹è¯•ä¿¡æ¯
- **æµ‹è¯•æ—¶é—´**: 2026-02-07T12:37:44.895027
- **æµ‹è¯•æ–‡ä»¶**: `sample_test.txt`
- **æ–‡ä»¶å¤§å°**: 922 B
- **æµ‹è¯•å¼•æ“æ•°é‡**: 8

## æ•´ä½“ç»Ÿè®¡
- **æˆåŠŸ**: 5 ä¸ªå¼•æ“
- **å¤±è´¥**: 3 ä¸ªå¼•æ“
- **æˆåŠŸç‡**: 62.5%

## æ€§èƒ½æ’åï¼ˆæŒ‰è½¬æ¢æ—¶é—´ï¼‰
1. **local** (local-text-wrapper)
   - è½¬æ¢æ—¶é—´: < 0.01ç§’
   - è¾“å‡ºé•¿åº¦: 724 å­—ç¬¦
   - èµ„æºæ•°é‡: 0

2. **markitdown** (markitdown-default)
   - è½¬æ¢æ—¶é—´: 0.52ç§’
   - è¾“å‡ºé•¿åº¦: 1,245 å­—ç¬¦
   - èµ„æºæ•°é‡: 0

...
```

## è¾“å‡ºæ–‡ä»¶ / Output Files

è¿è¡ŒåŸºå‡†æµ‹è¯•åï¼Œä¼šåœ¨è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä¸º`benchmark_results/`ï¼‰ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

After running the benchmark, the following files are generated in the output directory (default: `benchmark_results/`):

1. **comparison_report_YYYYMMDD_HHMMSS.md** - ä¸­æ–‡å¯¹æ¯”æŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰
2. **benchmark_result_YYYYMMDD_HHMMSS.json** - åŸå§‹æµ‹è¯•æ•°æ®ï¼ˆJSONæ ¼å¼ï¼Œä½¿ç”¨`--save-json`æ—¶ç”Ÿæˆï¼‰
3. **sample_test.txt** - ç¤ºä¾‹æµ‹è¯•æ–‡ä»¶ï¼ˆå¦‚æœæœªæä¾›è‡ªå®šä¹‰æµ‹è¯•æ–‡ä»¶ï¼‰

## ä½¿ç”¨åœºæ™¯ / Use Cases

### åœºæ™¯1ï¼šé€‰æ‹©åˆé€‚çš„å¼•æ“ / Scenario 1: Choosing the Right Engine

å¦‚æœä½ ä¸ç¡®å®šåº”è¯¥ä½¿ç”¨å“ªä¸ªå¼•æ“ï¼Œå¯ä»¥è¿è¡Œå®Œæ•´çš„åŸºå‡†æµ‹è¯•ï¼š

```bash
python benchmark.py --test-file your_document.pdf --save-json
```

æ ¹æ®æŠ¥å‘Šä¸­çš„æ€§èƒ½æ’åå’Œç‰¹ç‚¹åˆ†æï¼Œé€‰æ‹©æœ€é€‚åˆä½ éœ€æ±‚çš„å¼•æ“ã€‚

### åœºæ™¯2ï¼šæ€§èƒ½éªŒè¯ / Scenario 2: Performance Validation

åœ¨ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å‰ï¼ŒéªŒè¯å¼•æ“æ€§èƒ½ï¼š

```bash
python benchmark.py \
  --test-file production_sample.pdf \
  --engines mistral deepseekocr \
  --output-dir validation_results
```

### åœºæ™¯3ï¼šè´¨é‡è¯„ä¼° / Scenario 3: Quality Assessment

å¯¹æ¯”ä¸åŒå¼•æ“çš„è¾“å‡ºè´¨é‡ï¼š

```bash
python benchmark.py \
  --test-file complex_document.pdf \
  --engines local markitdown mistral paddleocr docling marker
```

æŸ¥çœ‹æŠ¥å‘Šä¸­çš„"Markdowné•¿åº¦"å’Œ"èµ„æºæ•°é‡"ï¼Œè¾“å‡ºè¶Šè¯¦ç»†é€šå¸¸è´¨é‡è¶Šé«˜ã€‚

### åœºæ™¯4ï¼šæˆæœ¬åˆ†æ / Scenario 4: Cost Analysis

è¯„ä¼°å…è´¹å¼•æ“å’Œä»˜è´¹å¼•æ“çš„æ€§èƒ½å·®å¼‚ï¼š

```bash
# æµ‹è¯•å…è´¹å¼•æ“
python benchmark.py --engines local markitdown paddleocr docling marker mineru

# æµ‹è¯•ä»˜è´¹å¼•æ“
python benchmark.py --engines mistral deepseekocr
```

## å¸¸è§é—®é¢˜ / FAQ

### Q: ä¸ºä»€ä¹ˆæŸäº›å¼•æ“æµ‹è¯•å¤±è´¥ï¼Ÿ
### Q: Why do some engines fail in testing?

**A:** å¯èƒ½çš„åŸå› ï¼š
- ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…ï¼ˆå¦‚markitdownã€paddleocrç­‰ï¼‰
- æœªé…ç½®APIå¯†é’¥ï¼ˆå¯¹äºmistralã€deepseekocrï¼‰
- æµ‹è¯•æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ
- ç³»ç»Ÿèµ„æºä¸è¶³ï¼ˆç‰¹åˆ«æ˜¯GPUç›¸å…³çš„å¼•æ“ï¼‰

**è§£å†³æ–¹æ³•**ï¼š
1. æŸ¥çœ‹æŠ¥å‘Šä¸­çš„"å¤±è´¥è¯¦æƒ…"éƒ¨åˆ†
2. å®‰è£…ç¼ºå¤±çš„ä¾èµ–ï¼š`pip install markitdown` æˆ– `pip install ".[markitdown]"`
3. é…ç½®APIå¯†é’¥ï¼šç¼–è¾‘`.env`æ–‡ä»¶
4. ç¡®è®¤æµ‹è¯•æ–‡ä»¶æ ¼å¼æ­£ç¡®

### Q: å¦‚ä½•åªæµ‹è¯•å·²å®‰è£…çš„å¼•æ“ï¼Ÿ
### Q: How to test only installed engines?

**A:** ä½¿ç”¨`--engines`å‚æ•°æ˜ç¡®æŒ‡å®šè¦æµ‹è¯•çš„å¼•æ“ï¼š

```bash
python benchmark.py --engines local markitdown
```

### Q: æµ‹è¯•ç»“æœä¿å­˜åœ¨å“ªé‡Œï¼Ÿ
### Q: Where are test results saved?

**A:** é»˜è®¤ä¿å­˜åœ¨`benchmark_results/`ç›®å½•ã€‚å¯ä»¥ä½¿ç”¨`--output-dir`å‚æ•°è‡ªå®šä¹‰ï¼š

```bash
python benchmark.py --output-dir my_results
```

### Q: å¦‚ä½•è§£è¯»æ€§èƒ½è¯„çº§ï¼Ÿ
### Q: How to interpret performance ratings?

**A:** æ€§èƒ½è¯„çº§åŸºäºè½¬æ¢æ—¶é—´ï¼š
- â­â­â­â­â­ ä¼˜ç§€ï¼š< 5ç§’
- â­â­â­â­ è‰¯å¥½ï¼š5-15ç§’
- â­â­â­ ä¸€èˆ¬ï¼š15-30ç§’
- â­â­ è¾ƒæ…¢ï¼š30-60ç§’
- â­ ç¼“æ…¢ï¼š> 60ç§’

### Q: å¯ä»¥ç”¨è‡ªå·±çš„æ–‡æ¡£æµ‹è¯•å—ï¼Ÿ
### Q: Can I test with my own documents?

**A:** å½“ç„¶å¯ä»¥ï¼ä½¿ç”¨`--test-file`å‚æ•°ï¼š

```bash
python benchmark.py --test-file path/to/your/document.pdf
```

æ”¯æŒçš„æ ¼å¼ï¼š.pdf, .docx, .png, .jpg, .jpeg, .txt, .md

### Q: å¦‚ä½•å¯¹æ¯”ä¸­æ–‡æ–‡æ¡£çš„å¤„ç†èƒ½åŠ›ï¼Ÿ
### Q: How to compare Chinese document processing?

**A:** ä½¿ç”¨åŒ…å«ä¸­æ–‡å†…å®¹çš„æµ‹è¯•æ–‡ä»¶ï¼Œç‰¹åˆ«æ¨èæµ‹è¯•è¿™äº›å¼•æ“ï¼š

```bash
python benchmark.py \
  --test-file chinese_document.pdf \
  --engines deepseekocr paddleocr docling mistral
```

DeepSeek OCR å’Œ PaddleOCR å¯¹ä¸­æ–‡æ”¯æŒè¾ƒå¥½ã€‚

## æŠ€æœ¯ç»†èŠ‚ / Technical Details

### æµ‹è¯•æŒ‡æ ‡ / Test Metrics

1. **è½¬æ¢æ—¶é—´** (Conversion Time)
   - ä»å¼€å§‹è½¬æ¢åˆ°å®Œæˆçš„æ€»æ—¶é—´
   - ä¸åŒ…æ‹¬å¼•æ“åˆå§‹åŒ–æ—¶é—´
   - å•ä½ï¼šç§’

2. **Markdowné•¿åº¦** (Markdown Length)
   - è¾“å‡ºMarkdownæ–‡æœ¬çš„å­—ç¬¦æ•°
   - é€šå¸¸è¶Šé•¿è¡¨ç¤ºæå–çš„å†…å®¹è¶Šè¯¦ç»†
   - å•ä½ï¼šå­—ç¬¦

3. **èµ„æºæ•°é‡** (Asset Count)
   - æå–çš„å›¾åƒå’Œå…¶ä»–èµ„æºæ–‡ä»¶æ•°é‡
   - åŒ…æ‹¬OCRè¿‡ç¨‹ä¸­æå–çš„å›¾ç‰‡
   - å•ä½ï¼šä¸ª

4. **æˆåŠŸç‡** (Success Rate)
   - æˆåŠŸè½¬æ¢çš„å¼•æ“æ•°é‡å æ€»æµ‹è¯•å¼•æ“æ•°çš„ç™¾åˆ†æ¯”
   - å•ä½ï¼šç™¾åˆ†æ¯”

### æ€§èƒ½ä¼˜åŒ–å»ºè®® / Performance Optimization Tips

1. **æœ¬åœ°å¼•æ“**ï¼š
   - PaddleOCRå¯ä»¥ä½¿ç”¨GPUåŠ é€Ÿï¼šè®¾ç½®ç¯å¢ƒå˜é‡`use_gpu=True`
   - MinerUåœ¨GPUç¯å¢ƒä¸‹æ€§èƒ½æ›´å¥½
   - Markerå¯ä»¥å¯ç”¨å¹¶è¡Œå¤„ç†

2. **äº‘ç«¯å¼•æ“**ï¼š
   - è°ƒæ•´è¶…æ—¶è®¾ç½®ï¼šåœ¨`.env`ä¸­è®¾ç½®`*_TIMEOUT_SECONDS`
   - è°ƒæ•´é‡è¯•æ¬¡æ•°ï¼šè®¾ç½®`*_RETRY_ATTEMPTS`
   - å¤§æ–‡æ¡£å¯èƒ½éœ€è¦åˆ†å—å¤„ç†

3. **æµ‹è¯•å»ºè®®**ï¼š
   - é¦–æ¬¡æµ‹è¯•ä½¿ç”¨å°æ–‡ä»¶ï¼ˆ< 1MBï¼‰
   - é€æ­¥å¢åŠ æ–‡æ¡£å¤æ‚åº¦
   - ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ

## è´¡çŒ® / Contributing

å¦‚æœä½ æƒ³ä¸ºåŸºå‡†æµ‹è¯•å·¥å…·æ·»åŠ æ–°åŠŸèƒ½æˆ–æ”¹è¿›ï¼Œæ¬¢è¿æäº¤Pull Requestï¼

å»ºè®®çš„æ”¹è¿›æ–¹å‘ï¼š
- æ·»åŠ æ›´å¤šæ€§èƒ½æŒ‡æ ‡ï¼ˆå†…å­˜ä½¿ç”¨ã€CPUå ç”¨ç­‰ï¼‰
- æ”¯æŒæ‰¹é‡æ–‡æ¡£æµ‹è¯•
- æ·»åŠ å¯è§†åŒ–å›¾è¡¨
- æ”¯æŒæ›´å¤šè¾“å‡ºæ ¼å¼ï¼ˆHTMLã€Excelç­‰ï¼‰

## è®¸å¯ / License

æœ¬å·¥å…·éµå¾ªé¡¹ç›®çš„æ•´ä½“è®¸å¯åè®®ã€‚

---

**æ›´å¤šä¿¡æ¯** / For more informationï¼š
- æŸ¥çœ‹ä¸»READMEæ–‡ä»¶ï¼š`README.md`
- æŸ¥çœ‹å¼•æ“é…ç½®ï¼š`.env.example`
- æŸ¥çœ‹ä»£ç å®ç°ï¼š`benchmark.py`
