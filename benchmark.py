#!/usr/bin/env python3
"""
å¼•æ“å¯¹æ¯”æµ‹è¯•å·¥å…· (Engine Comparison Benchmark Tool)

æ­¤è„šæœ¬ç”¨äºæµ‹è¯•å’Œå¯¹æ¯”ä¸åŒæ–‡æ¡£è½¬æ¢å¼•æ“çš„æ€§èƒ½å’Œè´¨é‡ã€‚
This script tests and compares the performance and quality of different document conversion engines.
"""
from __future__ import annotations

import json
import sys
import time
from dataclasses import asdict, dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any

# Ensure project root is importable
PROJECT_ROOT = Path(__file__).resolve().parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from config.settings import EngineName, get_settings
from doc_to_md.cli import ENGINE_REGISTRY
from doc_to_md.engines.base import Engine, EngineResponse


@dataclass
class EngineResult:
    """å•ä¸ªå¼•æ“çš„æµ‹è¯•ç»“æœ"""
    engine_name: str
    model: str
    success: bool
    conversion_time: float
    markdown_length: int = 0
    num_assets: int = 0
    error_message: str | None = None


@dataclass
class BenchmarkResult:
    """å®Œæ•´çš„åŸºå‡†æµ‹è¯•ç»“æœ"""
    timestamp: str
    test_file: str
    file_size_bytes: int
    results: list[EngineResult] = field(default_factory=list)
    
    def to_dict(self) -> dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'timestamp': self.timestamp,
            'test_file': self.test_file,
            'file_size_bytes': self.file_size_bytes,
            'results': [asdict(r) for r in self.results]
        }


class EngineBenchmark:
    """å¼•æ“åŸºå‡†æµ‹è¯•ç±»"""
    
    def __init__(self, engines_to_test: list[tuple[EngineName, str | None]] | None = None):
        """
        åˆå§‹åŒ–åŸºå‡†æµ‹è¯•
        
        Args:
            engines_to_test: è¦æµ‹è¯•çš„å¼•æ“åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [(engine_name, model), ...]
                           å¦‚æœä¸º Noneï¼Œå°†æµ‹è¯•æ‰€æœ‰å¯ç”¨å¼•æ“
        """
        self.settings = get_settings()
        
        if engines_to_test is None:
            # é»˜è®¤æµ‹è¯•æ‰€æœ‰å¼•æ“
            self.engines_to_test = [
                ("local", None),
                ("markitdown", None),
                ("paddleocr", None),
                ("docling", None),
                ("marker", None),
                ("mineru", None),
                ("mistral", self.settings.mistral_default_model),
                ("deepseekocr", self.settings.siliconflow_default_model),
            ]
        else:
            self.engines_to_test = engines_to_test
    
    def _create_engine(self, engine_name: EngineName, model: str | None) -> Engine | None:
        """åˆ›å»ºå¼•æ“å®ä¾‹"""
        try:
            engine_cls = ENGINE_REGISTRY.get(engine_name)
            if engine_cls is None:
                return None
            
            # æŸäº›å¼•æ“éœ€è¦ model å‚æ•°
            if engine_name in {"deepseekocr", "mistral", "markitdown", "paddleocr", "mineru", "docling", "marker"}:
                return engine_cls(model=model)
            return engine_cls()
        except Exception as e:
            print(f"âŒ æ— æ³•åˆ›å»ºå¼•æ“ {engine_name}: {e}")
            return None
    
    def test_engine(self, engine_name: EngineName, model: str | None, test_file: Path) -> EngineResult:
        """
        æµ‹è¯•å•ä¸ªå¼•æ“
        
        Args:
            engine_name: å¼•æ“åç§°
            model: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
            test_file: æµ‹è¯•æ–‡ä»¶è·¯å¾„
        
        Returns:
            EngineResult: æµ‹è¯•ç»“æœ
        """
        print(f"\nğŸ“Š æµ‹è¯•å¼•æ“: {engine_name} (model: {model or 'default'})")
        
        # åˆ›å»ºå¼•æ“å®ä¾‹
        engine = self._create_engine(engine_name, model)
        if engine is None:
            return EngineResult(
                engine_name=engine_name,
                model=model or "default",
                success=False,
                conversion_time=0.0,
                error_message="æ— æ³•åˆ›å»ºå¼•æ“å®ä¾‹ (å¯èƒ½ç¼ºå°‘ä¾èµ–æˆ–é…ç½®)"
            )
        
        # æ‰§è¡Œè½¬æ¢å¹¶è®¡æ—¶
        try:
            start_time = time.time()
            response: EngineResponse = engine.convert(test_file)
            conversion_time = time.time() - start_time
            
            # æ”¶é›†ç»“æœ
            result = EngineResult(
                engine_name=engine_name,
                model=response.model,
                success=True,
                conversion_time=conversion_time,
                markdown_length=len(response.markdown),
                num_assets=len(response.assets)
            )
            
            print(f"âœ… æˆåŠŸ - è€—æ—¶: {conversion_time:.2f}ç§’, Markdowné•¿åº¦: {result.markdown_length}, èµ„æºæ•°: {result.num_assets}")
            return result
            
        except Exception as e:
            conversion_time = time.time() - start_time
            error_msg = f"{type(e).__name__}: {str(e)}"
            print(f"âŒ å¤±è´¥ - {error_msg}")
            return EngineResult(
                engine_name=engine_name,
                model=model or "default",
                success=False,
                conversion_time=conversion_time,
                error_message=error_msg
            )
    
    def run_benchmark(self, test_file: Path) -> BenchmarkResult:
        """
        è¿è¡Œå®Œæ•´çš„åŸºå‡†æµ‹è¯•
        
        Args:
            test_file: æµ‹è¯•æ–‡ä»¶è·¯å¾„
        
        Returns:
            BenchmarkResult: å®Œæ•´çš„æµ‹è¯•ç»“æœ
        """
        print(f"\n{'='*60}")
        print(f"å¼€å§‹åŸºå‡†æµ‹è¯•")
        print(f"æµ‹è¯•æ–‡ä»¶: {test_file}")
        print(f"æ–‡ä»¶å¤§å°: {test_file.stat().st_size / 1024:.2f} KB")
        print(f"{'='*60}")
        
        benchmark_result = BenchmarkResult(
            timestamp=datetime.now().isoformat(),
            test_file=str(test_file),
            file_size_bytes=test_file.stat().st_size
        )
        
        for engine_name, model in self.engines_to_test:
            result = self.test_engine(engine_name, model, test_file)
            benchmark_result.results.append(result)
        
        return benchmark_result


class ChineseReportGenerator:
    """ä¸­æ–‡å¯¹æ¯”æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, benchmark_result: BenchmarkResult):
        self.result = benchmark_result
    
    def _format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´"""
        if seconds < 0.01:
            return "< 0.01ç§’"
        return f"{seconds:.2f}ç§’"
    
    def _format_size(self, bytes_size: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if bytes_size < 1024:
            return f"{bytes_size} B"
        elif bytes_size < 1024 * 1024:
            return f"{bytes_size / 1024:.2f} KB"
        else:
            return f"{bytes_size / (1024 * 1024):.2f} MB"
    
    def _get_rating(self, time: float, success: bool) -> str:
        """è·å–æ€§èƒ½è¯„çº§"""
        if not success:
            return "âŒ å¤±è´¥"
        if time < 5:
            return "â­â­â­â­â­ ä¼˜ç§€"
        elif time < 15:
            return "â­â­â­â­ è‰¯å¥½"
        elif time < 30:
            return "â­â­â­ ä¸€èˆ¬"
        elif time < 60:
            return "â­â­ è¾ƒæ…¢"
        else:
            return "â­ ç¼“æ…¢"
    
    def generate_markdown_report(self) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„ä¸­æ–‡å¯¹æ¯”æŠ¥å‘Š"""
        lines = []
        
        # æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
        lines.append("# æ–‡æ¡£è½¬æ¢å¼•æ“å¯¹æ¯”æµ‹è¯•æŠ¥å‘Š")
        lines.append("")
        lines.append("## æµ‹è¯•ä¿¡æ¯")
        lines.append("")
        lines.append(f"- **æµ‹è¯•æ—¶é—´**: {self.result.timestamp}")
        lines.append(f"- **æµ‹è¯•æ–‡ä»¶**: `{self.result.test_file}`")
        lines.append(f"- **æ–‡ä»¶å¤§å°**: {self._format_size(self.result.file_size_bytes)}")
        lines.append(f"- **æµ‹è¯•å¼•æ“æ•°é‡**: {len(self.result.results)}")
        lines.append("")
        
        # æˆåŠŸç‡ç»Ÿè®¡
        successful = sum(1 for r in self.result.results if r.success)
        failed = len(self.result.results) - successful
        success_rate = (successful / len(self.result.results) * 100) if self.result.results else 0
        
        lines.append("## æ•´ä½“ç»Ÿè®¡")
        lines.append("")
        lines.append(f"- **æˆåŠŸ**: {successful} ä¸ªå¼•æ“")
        lines.append(f"- **å¤±è´¥**: {failed} ä¸ªå¼•æ“")
        lines.append(f"- **æˆåŠŸç‡**: {success_rate:.1f}%")
        lines.append("")
        
        # æ€§èƒ½æ’å
        successful_results = [r for r in self.result.results if r.success]
        if successful_results:
            lines.append("## æ€§èƒ½æ’åï¼ˆæŒ‰è½¬æ¢æ—¶é—´ï¼‰")
            lines.append("")
            sorted_results = sorted(successful_results, key=lambda r: r.conversion_time)
            for i, result in enumerate(sorted_results, 1):
                lines.append(f"{i}. **{result.engine_name}** ({result.model})")
                lines.append(f"   - è½¬æ¢æ—¶é—´: {self._format_time(result.conversion_time)}")
                lines.append(f"   - è¾“å‡ºé•¿åº¦: {result.markdown_length:,} å­—ç¬¦")
                lines.append(f"   - èµ„æºæ•°é‡: {result.num_assets}")
                lines.append("")
        
        # è¯¦ç»†æµ‹è¯•ç»“æœè¡¨æ ¼
        lines.append("## è¯¦ç»†æµ‹è¯•ç»“æœ")
        lines.append("")
        lines.append("| å¼•æ“åç§° | æ¨¡å‹ | çŠ¶æ€ | è½¬æ¢æ—¶é—´ | Markdowné•¿åº¦ | èµ„æºæ•° | æ€§èƒ½è¯„çº§ |")
        lines.append("|---------|------|------|---------|------------|-------|---------|")
        
        for result in self.result.results:
            status = "âœ… æˆåŠŸ" if result.success else "âŒ å¤±è´¥"
            time_str = self._format_time(result.conversion_time) if result.success else "-"
            md_len = f"{result.markdown_length:,}" if result.success else "-"
            assets = str(result.num_assets) if result.success else "-"
            rating = self._get_rating(result.conversion_time, result.success)
            
            lines.append(
                f"| {result.engine_name} | {result.model} | {status} | "
                f"{time_str} | {md_len} | {assets} | {rating} |"
            )
        
        lines.append("")
        
        # é”™è¯¯ä¿¡æ¯
        failed_results = [r for r in self.result.results if not r.success]
        if failed_results:
            lines.append("## å¤±è´¥è¯¦æƒ…")
            lines.append("")
            for result in failed_results:
                lines.append(f"### {result.engine_name} ({result.model})")
                lines.append("")
                lines.append("```")
                lines.append(result.error_message or "æœªçŸ¥é”™è¯¯")
                lines.append("```")
                lines.append("")
        
        # å¼•æ“ç‰¹ç‚¹åˆ†æ
        lines.append("## å¼•æ“ç‰¹ç‚¹åˆ†æ")
        lines.append("")
        
        engine_descriptions = {
            "local": {
                "name": "æœ¬åœ°å¼•æ“",
                "pros": ["æ— éœ€å¤–éƒ¨ä¾èµ–", "å¿«é€Ÿç®€å•", "é€‚åˆçº¯æ–‡æœ¬æ–‡æ¡£", "æ— ç½‘ç»œè¯·æ±‚"],
                "cons": ["OCRèƒ½åŠ›æœ‰é™", "æ ¼å¼æ”¯æŒè¾ƒå°‘", "è¾“å‡ºè´¨é‡ä¸€èˆ¬"],
                "best_for": "çº¯æ–‡æœ¬æ–‡ä»¶ã€å¿«é€Ÿæµ‹è¯•ã€ç¦»çº¿ç¯å¢ƒ"
            },
            "mistral": {
                "name": "Mistral OCR",
                "pros": ["å¼ºå¤§çš„OCRèƒ½åŠ›", "æ”¯æŒå›¾åƒæå–", "é«˜è´¨é‡è¾“å‡º", "æ”¯æŒå¤šç§æ ¼å¼"],
                "cons": ["éœ€è¦APIå¯†é’¥", "æœ‰ç½‘ç»œå»¶è¿Ÿ", "å¯èƒ½æœ‰æˆæœ¬", "ä¾èµ–å¤–éƒ¨æœåŠ¡"],
                "best_for": "å¤æ‚PDFæ–‡æ¡£ã€é«˜è´¨é‡OCRéœ€æ±‚ã€æœ‰é¢„ç®—çš„é¡¹ç›®"
            },
            "deepseekocr": {
                "name": "DeepSeek OCR",
                "pros": ["ä¼˜ç§€çš„ä¸­æ–‡OCR", "è§†è§‰ç†è§£èƒ½åŠ›å¼º", "æ”¯æŒå¤æ‚å¸ƒå±€", "è¾“å‡ºè´¨é‡é«˜"],
                "cons": ["éœ€è¦APIå¯†é’¥", "ç½‘ç»œä¾èµ–", "å¤„ç†é€Ÿåº¦å¯èƒ½è¾ƒæ…¢"],
                "best_for": "ä¸­æ–‡æ–‡æ¡£ã€å¤æ‚æ’ç‰ˆã€éœ€è¦é«˜ç²¾åº¦çš„åœºæ™¯"
            },
            "markitdown": {
                "name": "MarkItDown",
                "pros": ["æ”¯æŒå¤šç§Officeæ ¼å¼", "æœ¬åœ°å¤„ç†", "å¿«é€Ÿ", "ä¿çœŸåº¦é«˜"],
                "cons": ["å¯¹æ‰«æPDFæ”¯æŒæœ‰é™", "éœ€è¦å®‰è£…ä¾èµ–", "æ’ä»¶å¯èƒ½ä¸ç¨³å®š"],
                "best_for": "Officeæ–‡æ¡£ï¼ˆDOCXã€PPTXã€XLSXï¼‰ã€æœ¬åœ°å¤„ç†éœ€æ±‚"
            },
            "paddleocr": {
                "name": "PaddleOCR",
                "pros": ["æœ¬åœ°OCR", "æ”¯æŒå¤šè¯­è¨€", "å¯GPUåŠ é€Ÿ", "å¼€æºå…è´¹"],
                "cons": ["éœ€è¦å¤§é‡ä¾èµ–", "é¦–æ¬¡ä½¿ç”¨éœ€ä¸‹è½½æ¨¡å‹", "å‡†ç¡®åº¦ä¸­ç­‰"],
                "best_for": "æœ¬åœ°OCRéœ€æ±‚ã€æ‰¹é‡å¤„ç†ã€ä¸­æ–‡æ–‡æ¡£"
            },
            "docling": {
                "name": "Docling",
                "pros": ["IBMä¼ä¸šçº§æ–¹æ¡ˆ", "ç»“æ„åŒ–æå–", "æ”¯æŒå¤æ‚æ–‡æ¡£", "é«˜è´¨é‡è¾“å‡º"],
                "cons": ["ä¾èµ–è¾ƒé‡", "å¤„ç†é€Ÿåº¦è¾ƒæ…¢", "é…ç½®å¤æ‚"],
                "best_for": "ä¼ä¸šæ–‡æ¡£ã€ç»“æ„åŒ–æå–ã€éœ€è¦é«˜è´¨é‡çš„åœºæ™¯"
            },
            "marker": {
                "name": "Marker",
                "pros": ["ä¸“æ³¨PDFè½¬æ¢", "ä¿ç•™æ ¼å¼", "æ”¯æŒLLMå¢å¼º", "å›¾åƒæå–"],
                "cons": ["ä¾èµ–é‡", "å¯èƒ½éœ€è¦GPU", "å¤„ç†é€Ÿåº¦ä¸€èˆ¬"],
                "best_for": "å­¦æœ¯è®ºæ–‡ã€å¤æ‚PDFã€éœ€è¦ä¿ç•™æ ¼å¼"
            },
            "mineru": {
                "name": "MinerU",
                "pros": ["å¤šç§è§£ææ–¹æ³•", "GPUåŠ é€Ÿ", "æ”¯æŒå¤æ‚å¸ƒå±€", "å¼€æº"],
                "cons": ["ä¾èµ–é‡", "é…ç½®å¤æ‚", "èµ„æºæ¶ˆè€—å¤§"],
                "best_for": "ç ”ç©¶ç”¨é€”ã€æ‰¹é‡å¤„ç†ã€æœ‰GPUç¯å¢ƒ"
            }
        }
        
        for result in self.result.results:
            if result.engine_name in engine_descriptions:
                desc = engine_descriptions[result.engine_name]
                lines.append(f"### {desc['name']} (`{result.engine_name}`)")
                lines.append("")
                
                status_emoji = "âœ…" if result.success else "âŒ"
                lines.append(f"**æµ‹è¯•çŠ¶æ€**: {status_emoji} {'æˆåŠŸ' if result.success else 'å¤±è´¥'}")
                lines.append("")
                
                lines.append("**ä¼˜ç‚¹**:")
                for pro in desc["pros"]:
                    lines.append(f"- {pro}")
                lines.append("")
                
                lines.append("**ç¼ºç‚¹**:")
                for con in desc["cons"]:
                    lines.append(f"- {con}")
                lines.append("")
                
                lines.append(f"**æœ€é€‚åˆ**: {desc['best_for']}")
                lines.append("")
        
        # ä½¿ç”¨å»ºè®®
        lines.append("## ä½¿ç”¨å»ºè®®")
        lines.append("")
        lines.append("æ ¹æ®æµ‹è¯•ç»“æœï¼Œæˆ‘ä»¬æä¾›ä»¥ä¸‹ä½¿ç”¨å»ºè®®ï¼š")
        lines.append("")
        
        if successful_results:
            fastest = min(successful_results, key=lambda r: r.conversion_time)
            lines.append(f"1. **é€Ÿåº¦ä¼˜å…ˆ**: ä½¿ç”¨ `{fastest.engine_name}` å¼•æ“ï¼ˆ{self._format_time(fastest.conversion_time)}ï¼‰")
            lines.append("")
            
            # æ‰¾åˆ°è¾“å‡ºæœ€é•¿çš„ï¼ˆé€šå¸¸æ„å‘³ç€æœ€è¯¦ç»†ï¼‰
            longest = max(successful_results, key=lambda r: r.markdown_length)
            lines.append(f"2. **è´¨é‡ä¼˜å…ˆ**: ä½¿ç”¨ `{longest.engine_name}` å¼•æ“ï¼ˆè¾“å‡º {longest.markdown_length:,} å­—ç¬¦ï¼‰")
            lines.append("")
        
        lines.append("3. **æˆæœ¬è€ƒè™‘**:")
        lines.append("   - å…è´¹æ–¹æ¡ˆ: `local`, `markitdown`, `paddleocr`, `docling`, `marker`, `mineru`")
        lines.append("   - ä»˜è´¹æ–¹æ¡ˆ: `mistral`, `deepseekocr`ï¼ˆéœ€è¦APIå¯†é’¥ï¼‰")
        lines.append("")
        
        lines.append("4. **æ–‡æ¡£ç±»å‹å»ºè®®**:")
        lines.append("   - çº¯æ–‡æœ¬/ç®€å•æ–‡æ¡£: `local` æˆ– `markitdown`")
        lines.append("   - Officeæ–‡æ¡£: `markitdown`")
        lines.append("   - æ‰«æPDF/å›¾ç‰‡: `mistral`, `deepseekocr`, æˆ– `paddleocr`")
        lines.append("   - å¤æ‚å­¦æœ¯PDF: `marker` æˆ– `docling`")
        lines.append("   - ä¸­æ–‡æ–‡æ¡£: `deepseekocr` æˆ– `paddleocr`")
        lines.append("")
        
        # ç»“è®º
        lines.append("## ç»“è®º")
        lines.append("")
        lines.append(f"æœ¬æ¬¡æµ‹è¯•å…±è¯„ä¼°äº† {len(self.result.results)} ä¸ªæ–‡æ¡£è½¬æ¢å¼•æ“ï¼Œ"
                    f"æˆåŠŸç‡ä¸º {success_rate:.1f}%ã€‚")
        lines.append("")
        
        if successful_results:
            lines.append("æ¯ä¸ªå¼•æ“éƒ½æœ‰å…¶ç‰¹å®šçš„ä¼˜åŠ¿å’Œé€‚ç”¨åœºæ™¯ã€‚é€‰æ‹©åˆé€‚çš„å¼•æ“éœ€è¦ç»¼åˆè€ƒè™‘ï¼š")
            lines.append("")
            lines.append("- æ–‡æ¡£ç±»å‹å’Œå¤æ‚åº¦")
            lines.append("- å¤„ç†é€Ÿåº¦è¦æ±‚")
            lines.append("- è¾“å‡ºè´¨é‡è¦æ±‚")
            lines.append("- æˆæœ¬é¢„ç®—")
            lines.append("- æ˜¯å¦éœ€è¦ç¦»çº¿å¤„ç†")
            lines.append("- è¯­è¨€æ”¯æŒï¼ˆç‰¹åˆ«æ˜¯ä¸­æ–‡ï¼‰")
        else:
            lines.append("âš ï¸ æ‰€æœ‰å¼•æ“éƒ½å¤±è´¥äº†ã€‚è¯·æ£€æŸ¥ï¼š")
            lines.append("- æµ‹è¯•æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ")
            lines.append("- å¿…è¦çš„ä¾èµ–æ˜¯å¦å·²å®‰è£…")
            lines.append("- APIå¯†é’¥æ˜¯å¦å·²é…ç½®ï¼ˆå¯¹äºè¿œç¨‹å¼•æ“ï¼‰")
        
        lines.append("")
        lines.append("---")
        lines.append(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {self.result.timestamp}*")
        
        return "\n".join(lines)
    
    def save_report(self, output_path: Path) -> None:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        report = self.generate_markdown_report()
        output_path.write_text(report, encoding="utf-8")
        print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")


def create_sample_test_file(output_dir: Path) -> Path:
    """åˆ›å»ºç¤ºä¾‹æµ‹è¯•æ–‡ä»¶"""
    output_dir.mkdir(parents=True, exist_ok=True)
    test_file = output_dir / "sample_test.txt"
    
    content = """# æµ‹è¯•æ–‡æ¡£ - Document Conversion Test

è¿™æ˜¯ä¸€ä¸ªç”¨äºæµ‹è¯•æ–‡æ¡£è½¬æ¢å¼•æ“çš„ç¤ºä¾‹æ–‡ä»¶ã€‚
This is a sample file for testing document conversion engines.

## åŠŸèƒ½ç‰¹ç‚¹ / Features

1. å¤šå¼•æ“æ”¯æŒ - Multiple engine support
2. æ€§èƒ½å¯¹æ¯” - Performance comparison
3. è´¨é‡è¯„ä¼° - Quality assessment

## æŠ€æœ¯æ ˆ / Tech Stack

- Python 3.10+
- Typer (CLI framework)
- Pydantic (Configuration management)
- Multiple OCR/ML engines

## ä¸­è‹±æ–‡æ··åˆå†…å®¹ / Mixed Chinese-English Content

æ–‡æ¡£è½¬æ¢æ˜¯ä¸€ä¸ªå¤æ‚çš„ä»»åŠ¡ï¼Œéœ€è¦è€ƒè™‘å¤šä¸ªå› ç´ ï¼š
Document conversion is a complex task that requires considering multiple factors:

1. å‡†ç¡®æ€§ (Accuracy)
2. é€Ÿåº¦ (Speed)
3. æˆæœ¬ (Cost)
4. æ ¼å¼æ”¯æŒ (Format support)

æµ‹è¯•å†…å®¹åŒ…æ‹¬çº¯æ–‡æœ¬ã€ç‰¹æ®Šå­—ç¬¦ï¼ˆ@#$%^&*ï¼‰ã€æ•°å­—ï¼ˆ123456ï¼‰ç­‰ã€‚
Test content includes plain text, special characters (@#$%^&*), numbers (123456), etc.
"""
    
    test_file.write_text(content, encoding="utf-8")
    return test_file


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="æ–‡æ¡£è½¬æ¢å¼•æ“å¯¹æ¯”æµ‹è¯•å·¥å…· / Engine Comparison Benchmark Tool"
    )
    parser.add_argument(
        "--test-file",
        type=Path,
        help="æµ‹è¯•æ–‡ä»¶è·¯å¾„ / Path to test file (will create a sample if not provided)"
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path("benchmark_results"),
        help="è¾“å‡ºç›®å½• / Output directory (default: benchmark_results)"
    )
    parser.add_argument(
        "--engines",
        type=str,
        nargs="+",
        help="è¦æµ‹è¯•çš„å¼•æ“åˆ—è¡¨ / List of engines to test (e.g., local mistral deepseekocr)"
    )
    parser.add_argument(
        "--save-json",
        action="store_true",
        help="åŒæ—¶ä¿å­˜JSONæ ¼å¼ç»“æœ / Also save results in JSON format"
    )
    
    args = parser.parse_args()
    
    # å‡†å¤‡æµ‹è¯•æ–‡ä»¶
    if args.test_file and args.test_file.exists():
        test_file = args.test_file
        print(f"ä½¿ç”¨æµ‹è¯•æ–‡ä»¶: {test_file}")
    else:
        print("åˆ›å»ºç¤ºä¾‹æµ‹è¯•æ–‡ä»¶...")
        test_file = create_sample_test_file(args.output_dir)
        print(f"ç¤ºä¾‹æµ‹è¯•æ–‡ä»¶å·²åˆ›å»º: {test_file}")
    
    # å‡†å¤‡å¼•æ“åˆ—è¡¨
    engines_to_test = None
    if args.engines:
        settings = get_settings()
        engines_to_test = []
        for engine_name in args.engines:
            if engine_name in {"mistral"}:
                engines_to_test.append((engine_name, settings.mistral_default_model))
            elif engine_name in {"deepseekocr"}:
                engines_to_test.append((engine_name, settings.siliconflow_default_model))
            else:
                engines_to_test.append((engine_name, None))
        print(f"å°†æµ‹è¯•å¼•æ“: {', '.join(args.engines)}")
    else:
        print("å°†æµ‹è¯•æ‰€æœ‰å¯ç”¨å¼•æ“")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    args.output_dir.mkdir(parents=True, exist_ok=True)
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    benchmark = EngineBenchmark(engines_to_test)
    result = benchmark.run_benchmark(test_file)
    
    # ç”ŸæˆæŠ¥å‘Š
    print(f"\n{'='*60}")
    print("ç”Ÿæˆä¸­æ–‡å¯¹æ¯”æŠ¥å‘Š...")
    print(f"{'='*60}")
    
    generator = ChineseReportGenerator(result)
    
    # ä¿å­˜MarkdownæŠ¥å‘Š
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = args.output_dir / f"comparison_report_{timestamp}.md"
    generator.save_report(report_path)
    
    # å¯é€‰ï¼šä¿å­˜JSONæ ¼å¼
    if args.save_json:
        json_path = args.output_dir / f"benchmark_result_{timestamp}.json"
        json_path.write_text(
            json.dumps(result.to_dict(), ensure_ascii=False, indent=2),
            encoding="utf-8"
        )
        print(f"âœ… JSONç»“æœå·²ä¿å­˜åˆ°: {json_path}")
    
    print(f"\n{'='*60}")
    print("åŸºå‡†æµ‹è¯•å®Œæˆï¼")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
